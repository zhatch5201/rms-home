{"ast":null,"code":"\"use strict\";\n\nvar _wrapNativeSuper = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/wrapNativeSuper\");\n\nvar _regeneratorRuntime = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _inherits = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\n\nvar _createSuper = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createSuper\");\n\nvar _classCallCheck = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:/Users/Zack/Desktop/rms-home/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar assert = require(\"assert\");\n\nvar backoff_1 = require(\"./backoff\");\n\nvar rate_limiter_1 = require(\"./rate-limiter\");\n\nvar timestamp_1 = require(\"./timestamp\");\n\nvar util_1 = require(\"./util\");\n\nvar write_batch_1 = require(\"./write-batch\");\n\nvar validate_1 = require(\"./validate\");\n\nvar logger_1 = require(\"./logger\");\n\nvar google_gax_1 = require(\"google-gax\");\n/*!\n * The maximum number of writes that can be in a single batch.\n */\n\n\nvar MAX_BATCH_SIZE = 20;\n/*!\n * The starting maximum number of operations per second as allowed by the\n * 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nexports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND = 500;\n/*!\n * The rate by which to increase the capacity as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nvar RATE_LIMITER_MULTIPLIER = 1.5;\n/*!\n * How often the operations per second capacity should increase in milliseconds\n * as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nvar RATE_LIMITER_MULTIPLIER_MILLIS = 5 * 60 * 1000;\n/**\n * Represents a single write for BulkWriter, encapsulating operation dispatch\n * and error handling.\n * @private\n */\n\nvar BulkWriterOperation = /*#__PURE__*/function () {\n  /**\n   * @param ref The document reference being written to.\n   * @param type The type of operation that created this write.\n   * @param sendFn A callback to invoke when the operation should be sent.\n   * @param errorFn The user provided global error callback.\n   * @param successFn The user provided global success callback.\n   */\n  function BulkWriterOperation(ref, type, sendFn, errorFn, successFn) {\n    _classCallCheck(this, BulkWriterOperation);\n\n    this.ref = ref;\n    this.type = type;\n    this.sendFn = sendFn;\n    this.errorFn = errorFn;\n    this.successFn = successFn;\n    this.deferred = new util_1.Deferred();\n    this.failedAttempts = 0;\n  }\n\n  _createClass(BulkWriterOperation, [{\n    key: \"promise\",\n    get: function get() {\n      return this.deferred.promise;\n    }\n  }, {\n    key: \"onError\",\n    value: function onError(error) {\n      ++this.failedAttempts;\n\n      try {\n        var bulkWriterError = new BulkWriterError(error.code, error.message, this.ref, this.type, this.failedAttempts);\n        var shouldRetry = this.errorFn(bulkWriterError);\n        logger_1.logger('BulkWriter.errorFn', null, 'Ran error callback on error code:', error.code, ', shouldRetry:', shouldRetry, ' for document:', this.ref.path);\n\n        if (shouldRetry) {\n          this.sendFn(this);\n        } else {\n          this.deferred.reject(bulkWriterError);\n        }\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }, {\n    key: \"onSuccess\",\n    value: function onSuccess(result) {\n      try {\n        this.successFn(this.ref, result);\n        this.deferred.resolve(result);\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }]);\n\n  return BulkWriterOperation;\n}();\n/**\n * Used to represent a batch on the BatchQueue.\n *\n * @private\n */\n\n\nvar BulkCommitBatch = /*#__PURE__*/function (_write_batch_1$WriteB) {\n  _inherits(BulkCommitBatch, _write_batch_1$WriteB);\n\n  var _super = _createSuper(BulkCommitBatch);\n\n  function BulkCommitBatch() {\n    var _this;\n\n    _classCallCheck(this, BulkCommitBatch);\n\n    _this = _super.apply(this, arguments); // The set of document reference paths present in the WriteBatch.\n\n    _this.docPaths = new Set(); // An array of pending write operations. Only contains writes that have not\n    // been resolved.\n\n    _this.pendingOps = [];\n    return _this;\n  }\n\n  _createClass(BulkCommitBatch, [{\n    key: \"has\",\n    value: function has(documentRef) {\n      return this.docPaths.has(documentRef.path);\n    }\n  }, {\n    key: \"bulkCommit\",\n    value: function () {\n      var _bulkCommit = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var options,\n            _a,\n            tag,\n            stack,\n            response,\n            retryCodes,\n            ops,\n            i,\n            DELETE_TIMESTAMP_SENTINEL,\n            status,\n            updateTime,\n            error,\n            _args = arguments;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                options = _args.length > 0 && _args[0] !== undefined ? _args[0] : {};\n                tag = (_a = options === null || options === void 0 ? void 0 : options.requestTag) !== null && _a !== void 0 ? _a : util_1.requestTag(); // Capture the error stack to preserve stack tracing across async calls.\n\n                stack = Error().stack;\n                _context.prev = 3;\n                logger_1.logger('BulkCommitBatch.bulkCommit', tag, \"Sending next batch with \".concat(this._opCount, \" writes\"));\n                retryCodes = util_1.getRetryCodes('batchWrite');\n                _context.next = 8;\n                return this._commit({\n                  retryCodes: retryCodes,\n                  methodName: 'batchWrite',\n                  requestTag: tag\n                });\n\n              case 8:\n                response = _context.sent;\n                _context.next = 15;\n                break;\n\n              case 11:\n                _context.prev = 11;\n                _context.t0 = _context[\"catch\"](3);\n                // Map the failure to each individual write's result.\n                ops = Array.from({\n                  length: this.pendingOps.length\n                });\n                response = {\n                  writeResults: ops.map(function () {\n                    return {};\n                  }),\n                  status: ops.map(function () {\n                    return _context.t0;\n                  })\n                };\n\n              case 15:\n                for (i = 0; i < (response.writeResults || []).length; ++i) {\n                  // Since delete operations currently do not have write times, use a\n                  // sentinel Timestamp value.\n                  // TODO(b/158502664): Use actual delete timestamp.\n                  DELETE_TIMESTAMP_SENTINEL = timestamp_1.Timestamp.fromMillis(0);\n                  status = (response.status || [])[i];\n\n                  if (status.code === google_gax_1.Status.OK) {\n                    updateTime = timestamp_1.Timestamp.fromProto(response.writeResults[i].updateTime || DELETE_TIMESTAMP_SENTINEL);\n                    this.pendingOps[i].onSuccess(new write_batch_1.WriteResult(updateTime));\n                  } else {\n                    error = new google_gax_1.GoogleError(status.message || undefined);\n                    error.code = status.code;\n                    this.pendingOps[i].onError(util_1.wrapError(error, stack));\n                  }\n                }\n\n              case 16:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[3, 11]]);\n      }));\n\n      function bulkCommit() {\n        return _bulkCommit.apply(this, arguments);\n      }\n\n      return bulkCommit;\n    }()\n    /**\n     * Helper to update data structures associated with the operation and returns\n     * the result.\n     */\n\n  }, {\n    key: \"processLastOperation\",\n    value: function processLastOperation(op) {\n      assert(!this.docPaths.has(op.ref.path), 'Batch should not contain writes to the same document');\n      this.docPaths.add(op.ref.path);\n      this.pendingOps.push(op);\n    }\n  }]);\n\n  return BulkCommitBatch;\n}(write_batch_1.WriteBatch);\n/**\n * The error thrown when a BulkWriter operation fails.\n *\n * @class BulkWriterError\n */\n\n\nvar BulkWriterError = /*#__PURE__*/function (_Error) {\n  _inherits(BulkWriterError, _Error);\n\n  var _super2 = _createSuper(BulkWriterError);\n\n  /** @hideconstructor */\n  function BulkWriterError(\n  /** The status code of the error. */\n  code,\n  /** The error message of the error. */\n  message,\n  /** The document reference the operation was performed on. */\n  documentRef,\n  /** The type of operation performed. */\n  operationType,\n  /** How many times this operation has been attempted unsuccessfully. */\n  failedAttempts) {\n    var _this2;\n\n    _classCallCheck(this, BulkWriterError);\n\n    _this2 = _super2.call(this, message);\n    _this2.code = code;\n    _this2.message = message;\n    _this2.documentRef = documentRef;\n    _this2.operationType = operationType;\n    _this2.failedAttempts = failedAttempts;\n    return _this2;\n  }\n\n  return BulkWriterError;\n}( /*#__PURE__*/_wrapNativeSuper(Error));\n\nexports.BulkWriterError = BulkWriterError;\n/**\n * A Firestore BulkWriter that can be used to perform a large number of writes\n * in parallel.\n *\n * @class BulkWriter\n */\n\nvar BulkWriter = /*#__PURE__*/function () {\n  /** @hideconstructor */\n  function BulkWriter(firestore, options) {\n    _classCallCheck(this, BulkWriter);\n\n    var _a, _b;\n\n    this.firestore = firestore;\n    /**\n     * The maximum number of writes that can be in a single batch.\n     * Visible for testing.\n     * @private\n     */\n\n    this._maxBatchSize = MAX_BATCH_SIZE;\n    /**\n     * The batch that is currently used to schedule operations. Once this batch\n     * reaches maximum capacity, a new batch is created.\n     * @private\n     */\n\n    this._bulkCommitBatch = new BulkCommitBatch(this.firestore);\n    /**\n     * A pointer to the tail of all active BulkWriter applications. This pointer\n     * is advanced every time a new write is enqueued.\n     * @private\n     */\n\n    this._lastOp = Promise.resolve();\n    /**\n     * Whether this BulkWriter instance has started to close. Afterwards, no\n     * new operations can be enqueued, except for retry operations scheduled by\n     * the error handler.\n     * @private\n     */\n\n    this._closing = false;\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * successfully completes.\n     * @private\n     */\n\n    this._successFn = function () {};\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * fails.\n     * @private\n     */\n\n\n    this._errorFn = function (error) {\n      var retryCodes = util_1.getRetryCodes('batchWrite');\n      return error.code !== undefined && retryCodes.includes(error.code) && error.failedAttempts < backoff_1.MAX_RETRY_ATTEMPTS;\n    };\n\n    this.firestore._incrementBulkWritersCount();\n\n    validateBulkWriterOptions(options);\n\n    if ((options === null || options === void 0 ? void 0 : options.throttling) === false) {\n      this._rateLimiter = new rate_limiter_1.RateLimiter(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);\n    } else {\n      var startingRate = exports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND;\n      var maxRate = Number.POSITIVE_INFINITY;\n\n      if (typeof (options === null || options === void 0 ? void 0 : options.throttling) !== 'boolean') {\n        if (((_a = options === null || options === void 0 ? void 0 : options.throttling) === null || _a === void 0 ? void 0 : _a.maxOpsPerSecond) !== undefined) {\n          maxRate = options.throttling.maxOpsPerSecond;\n        }\n\n        if (((_b = options === null || options === void 0 ? void 0 : options.throttling) === null || _b === void 0 ? void 0 : _b.initialOpsPerSecond) !== undefined) {\n          startingRate = options.throttling.initialOpsPerSecond;\n        } // The initial validation step ensures that the maxOpsPerSecond is\n        // greater than initialOpsPerSecond. If this inequality is true, that\n        // means initialOpsPerSecond was not set and maxOpsPerSecond is less\n        // than the default starting rate.\n\n\n        if (maxRate < startingRate) {\n          startingRate = maxRate;\n        } // Ensure that the batch size is not larger than the number of allowed\n        // operations per second.\n\n\n        if (startingRate < this._maxBatchSize) {\n          this._maxBatchSize = startingRate;\n        }\n      }\n\n      this._rateLimiter = new rate_limiter_1.RateLimiter(startingRate, RATE_LIMITER_MULTIPLIER, RATE_LIMITER_MULTIPLIER_MILLIS, maxRate);\n    }\n  }\n  /**\n   * Create a document with the provided data. This single operation will fail\n   * if a document exists at its location.\n   *\n   * @param {DocumentReference} documentRef A reference to the document to be\n   * created.\n   * @param {T} data The object to serialize as the document.\n   * @returns {Promise<WriteResult>} A promise that resolves with the result of\n   * the write. If the write fails, the promise is rejected with a\n   * [BulkWriterError]{@link BulkWriterError}.\n   *\n   * @example\n   * let bulkWriter = firestore.bulkWriter();\n   * let documentRef = firestore.collection('col').doc();\n   *\n   * bulkWriter\n   *  .create(documentRef, {foo: 'bar'})\n   *  .then(result => {\n   *    console.log('Successfully executed write at: ', result);\n   *  })\n   *  .catch(err => {\n   *    console.log('Write failed with: ', err);\n   *  });\n   * });\n   */\n\n\n  _createClass(BulkWriter, [{\n    key: \"create\",\n    value: function create(documentRef, data) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'create', function (bulkCommitBatch) {\n        return bulkCommitBatch.create(documentRef, data);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Delete a document from the database.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * deleted.\n     * @param {Precondition=} precondition A precondition to enforce for this\n     * delete.\n     * @param {Timestamp=} precondition.lastUpdateTime If set, enforces that the\n     * document was last updated at lastUpdateTime. Fails the batch if the\n     * document doesn't exist or was last updated at a different time.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the delete. If the delete fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .delete(documentRef)\n     *  .then(result => {\n     *    console.log('Successfully deleted document');\n     *  })\n     *  .catch(err => {\n     *    console.log('Delete failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"delete\",\n    value: function _delete(documentRef, precondition) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'delete', function (bulkCommitBatch) {\n        return bulkCommitBatch.delete(documentRef, precondition);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Write to the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document does not\n     * exist yet, it will be created. If you pass [SetOptions]{@link SetOptions}.,\n     * the provided data can be merged into the existing document.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * set.\n     * @param {T} data The object to serialize as the document.\n     * @param {SetOptions=} options An object to configure the set behavior.\n     * @param {boolean=} options.merge - If true, set() merges the values\n     * specified in its data argument. Fields omitted from this set() call remain\n     * untouched.\n     * @param {Array.<string|FieldPath>=} options.mergeFields - If provided, set()\n     * only replaces the specified field paths. Any field path that is not\n     * specified is ignored and remains untouched.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .set(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(documentRef, data, options) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'set', function (bulkCommitBatch) {\n        return bulkCommitBatch.set(documentRef, data, options);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Update fields of the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document doesn't yet\n     * exist, the update fails and the entire batch will be rejected.\n     *\n     * The update() method accepts either an object with field paths encoded as\n     * keys and field values encoded as values, or a variable number of arguments\n     * that alternate between field paths and field values. Nested fields can be\n     * updated by providing dot-separated field path strings or by providing\n     * FieldPath objects.\n     *\n     *\n     * A Precondition restricting this update can be specified as the last\n     * argument.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * updated.\n     * @param {UpdateData|string|FieldPath} dataOrField An object containing the\n     * fields and values with which to update the document or the path of the\n     * first field to update.\n     * @param {...(Precondition|*|string|FieldPath)} preconditionOrValues - An\n     * alternating list of field paths and values to update or a Precondition to\n     * restrict this update\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .update(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"update\",\n    value: function update(documentRef, dataOrField) {\n      for (var _len = arguments.length, preconditionOrValues = new Array(_len > 2 ? _len - 2 : 0), _key = 2; _key < _len; _key++) {\n        preconditionOrValues[_key - 2] = arguments[_key];\n      }\n\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'update', function (bulkCommitBatch) {\n        return bulkCommitBatch.update.apply(bulkCommitBatch, [documentRef, dataOrField].concat(preconditionOrValues));\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Attaches a listener that is run every time a BulkWriter operation\n     * successfully completes.\n     *\n     * @param callback A callback to be called every time a BulkWriter operation\n     * successfully completes.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteResult((documentRef, result) => {\n     *     console.log(\n     *       'Successfully executed write on document: ',\n     *       documentRef,\n     *       ' at: ',\n     *       result\n     *     );\n     *   });\n     */\n\n  }, {\n    key: \"onWriteResult\",\n    value: function onWriteResult(callback) {\n      this._successFn = callback;\n    }\n    /**\n     * Attaches an error handler listener that is run every time a BulkWriter\n     * operation fails.\n     *\n     * BulkWriter has a default error handler that retries UNAVAILABLE and\n     * ABORTED errors up to a maximum of 10 failed attempts. When an error\n     * handler is specified, the default error handler will be overwritten.\n     *\n     * @param shouldRetryCallback A callback to be called every time a BulkWriter\n     * operation fails. Returning `true` will retry the operation. Returning\n     * `false` will stop the retry loop.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteError((error) => {\n     *     if (\n     *       error.code === GrpcStatus.UNAVAILABLE &&\n     *       error.failedAttempts < MAX_RETRY_ATTEMPTS\n     *     ) {\n     *       return true;\n     *     } else {\n     *       console.log('Failed write at document: ', error.documentRef);\n     *       return false;\n     *     }\n     *   });\n     */\n\n  }, {\n    key: \"onWriteError\",\n    value: function onWriteError(shouldRetryCallback) {\n      this._errorFn = shouldRetryCallback;\n    }\n    /**\n     * Commits all writes that have been enqueued up to this point in parallel.\n     *\n     * Returns a Promise that resolves when all currently queued operations have\n     * been committed. The Promise will never be rejected since the results for\n     * each individual operation are conveyed via their individual Promises.\n     *\n     * The Promise resolves immediately if there are no pending writes. Otherwise,\n     * the Promise waits for all previously issued writes, but it does not wait\n     * for writes that were added after the method is called. If you want to wait\n     * for additional writes, call `flush()` again.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await flush().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"flush\",\n    value: function flush() {\n      this._verifyNotClosed();\n\n      this._sendCurrentBatch(\n      /* flush= */\n      true);\n\n      return this._lastOp;\n    }\n    /**\n     * Commits all enqueued writes and marks the BulkWriter instance as closed.\n     *\n     * After calling `close()`, calling any method wil throw an error. Any\n     * retries scheduled as part of an `onWriteError()` handler will be run\n     * before the `close()` promise resolves.\n     *\n     * Returns a Promise that resolves when there are no more pending writes. The\n     * Promise will never be rejected. Calling this method will send all requests.\n     * The promise resolves immediately if there are no pending writes.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await close().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"close\",\n    value: function close() {\n      this._verifyNotClosed();\n\n      this.firestore._decrementBulkWritersCount();\n\n      var flushPromise = this.flush();\n      this._closing = true;\n      return flushPromise;\n    }\n    /**\n     * Throws an error if the BulkWriter instance has been closed.\n     * @private\n     */\n\n  }, {\n    key: \"_verifyNotClosed\",\n    value: function _verifyNotClosed() {\n      if (this._closing) {\n        throw new Error('BulkWriter has already been closed.');\n      }\n    }\n    /**\n     * Sends the current batch and resets `this._bulkCommitBatch`.\n     *\n     * @param flush If provided, keeps re-sending operations until no more\n     * operations are enqueued. This allows retries to resolve as part of a\n     * `flush()` or `close()` call.\n     * @private\n     */\n\n  }, {\n    key: \"_sendCurrentBatch\",\n    value: function _sendCurrentBatch() {\n      var _this3 = this;\n\n      var flush = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      if (this._bulkCommitBatch._opCount === 0) return;\n      var tag = util_1.requestTag();\n      var pendingBatch = this._bulkCommitBatch;\n      this._bulkCommitBatch = new BulkCommitBatch(this.firestore); // Send the batch if it is under the rate limit, or schedule another\n      // attempt after the appropriate timeout.\n\n      var underRateLimit = this._rateLimiter.tryMakeRequest(pendingBatch._opCount);\n\n      var delayedExecution = new util_1.Deferred();\n\n      if (underRateLimit) {\n        delayedExecution.resolve();\n      } else {\n        var delayMs = this._rateLimiter.getNextRequestDelayMs(pendingBatch._opCount);\n\n        logger_1.logger('BulkWriter._sendCurrentBatch', tag, \"Backing off for \".concat(delayMs, \" seconds\"));\n        backoff_1.delayExecution(function () {\n          return delayedExecution.resolve();\n        }, delayMs);\n      }\n\n      delayedExecution.promise.then( /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return pendingBatch.bulkCommit({\n                  requestTag: tag\n                });\n\n              case 2:\n                if (flush) _this3._sendCurrentBatch(flush);\n\n              case 3:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2);\n      })));\n    }\n    /**\n     * Schedules and runs the provided operation on the next available batch.\n     * @private\n     */\n\n  }, {\n    key: \"_enqueue\",\n    value: function _enqueue(ref, type, enqueueOnBatchCallback) {\n      var bulkWriterOp = new BulkWriterOperation(ref, type, this._sendFn.bind(this, enqueueOnBatchCallback), this._errorFn.bind(this), this._successFn.bind(this));\n\n      this._sendFn(enqueueOnBatchCallback, bulkWriterOp);\n\n      return bulkWriterOp.promise;\n    }\n    /**\n     * Schedules the provided operations on current BulkCommitBatch.\n     * Sends the BulkCommitBatch if it reaches maximum capacity.\n     *\n     * @private\n     */\n\n  }, {\n    key: \"_sendFn\",\n    value: function _sendFn(enqueueOnBatchCallback, op) {\n      if (this._bulkCommitBatch.has(op.ref)) {\n        // Create a new batch since the backend doesn't support batches with two\n        // writes to the same document.\n        this._sendCurrentBatch();\n      } // Run the operation on the current batch and advance the `_lastOp` pointer.\n      // This ensures that `_lastOp` only resolves when both the previous and the\n      // current write resolves.\n\n\n      enqueueOnBatchCallback(this._bulkCommitBatch);\n\n      this._bulkCommitBatch.processLastOperation(op);\n\n      this._lastOp = this._lastOp.then(function () {\n        return util_1.silencePromise(op.promise);\n      });\n\n      if (this._bulkCommitBatch._opCount === this._maxBatchSize) {\n        this._sendCurrentBatch();\n      }\n    }\n  }]);\n\n  return BulkWriter;\n}();\n\nexports.BulkWriter = BulkWriter;\n/**\n * Validates the use of 'value' as BulkWriterOptions.\n *\n * @private\n * @param value The BulkWriterOptions object to validate.\n * @throws if the input is not a valid BulkWriterOptions object.\n */\n\nfunction validateBulkWriterOptions(value) {\n  if (validate_1.validateOptional(value, {\n    optional: true\n  })) {\n    return;\n  }\n\n  var argName = 'options';\n\n  if (!util_1.isObject(value)) {\n    throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" Input is not an object.\"));\n  }\n\n  var options = value;\n\n  if (options.throttling === undefined || typeof options.throttling === 'boolean') {\n    return;\n  }\n\n  if (options.throttling.initialOpsPerSecond !== undefined) {\n    validate_1.validateInteger('initialOpsPerSecond', options.throttling.initialOpsPerSecond, {\n      minValue: 1\n    });\n  }\n\n  if (options.throttling.maxOpsPerSecond !== undefined) {\n    validate_1.validateInteger('maxOpsPerSecond', options.throttling.maxOpsPerSecond, {\n      minValue: 1\n    });\n\n    if (options.throttling.initialOpsPerSecond !== undefined && options.throttling.initialOpsPerSecond > options.throttling.maxOpsPerSecond) {\n      throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" \\\"maxOpsPerSecond\\\" cannot be less than \\\"initialOpsPerSecond\\\".\"));\n    }\n  }\n}","map":{"version":3,"sources":["C:/Users/Zack/Desktop/rms-home/node_modules/@google-cloud/firestore/build/src/bulk-writer.js"],"names":["Object","defineProperty","exports","value","assert","require","backoff_1","rate_limiter_1","timestamp_1","util_1","write_batch_1","validate_1","logger_1","google_gax_1","MAX_BATCH_SIZE","DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND","RATE_LIMITER_MULTIPLIER","RATE_LIMITER_MULTIPLIER_MILLIS","BulkWriterOperation","ref","type","sendFn","errorFn","successFn","deferred","Deferred","failedAttempts","promise","error","bulkWriterError","BulkWriterError","code","message","shouldRetry","logger","path","reject","userCallbackError","result","resolve","BulkCommitBatch","arguments","docPaths","Set","pendingOps","documentRef","has","options","tag","_a","requestTag","stack","Error","_opCount","retryCodes","getRetryCodes","_commit","methodName","response","ops","Array","from","length","writeResults","map","status","i","DELETE_TIMESTAMP_SENTINEL","Timestamp","fromMillis","Status","OK","updateTime","fromProto","onSuccess","WriteResult","GoogleError","undefined","onError","wrapError","op","add","push","WriteBatch","operationType","BulkWriter","firestore","_b","_maxBatchSize","_bulkCommitBatch","_lastOp","Promise","_closing","_successFn","_errorFn","includes","MAX_RETRY_ATTEMPTS","_incrementBulkWritersCount","validateBulkWriterOptions","throttling","_rateLimiter","RateLimiter","Number","POSITIVE_INFINITY","startingRate","maxRate","maxOpsPerSecond","initialOpsPerSecond","data","_verifyNotClosed","_enqueue","bulkCommitBatch","create","silencePromise","precondition","delete","set","dataOrField","preconditionOrValues","update","callback","shouldRetryCallback","_sendCurrentBatch","_decrementBulkWritersCount","flushPromise","flush","pendingBatch","underRateLimit","tryMakeRequest","delayedExecution","delayMs","getNextRequestDelayMs","delayExecution","then","bulkCommit","enqueueOnBatchCallback","bulkWriterOp","_sendFn","bind","processLastOperation","validateOptional","optional","argName","isObject","invalidArgumentMessage","validateInteger","minValue"],"mappings":"AAAA;;;;;;;;;;;;;;;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;;AACA,IAAMC,MAAM,GAAGC,OAAO,CAAC,QAAD,CAAtB;;AACA,IAAMC,SAAS,GAAGD,OAAO,CAAC,WAAD,CAAzB;;AACA,IAAME,cAAc,GAAGF,OAAO,CAAC,gBAAD,CAA9B;;AACA,IAAMG,WAAW,GAAGH,OAAO,CAAC,aAAD,CAA3B;;AACA,IAAMI,MAAM,GAAGJ,OAAO,CAAC,QAAD,CAAtB;;AACA,IAAMK,aAAa,GAAGL,OAAO,CAAC,eAAD,CAA7B;;AACA,IAAMM,UAAU,GAAGN,OAAO,CAAC,YAAD,CAA1B;;AACA,IAAMO,QAAQ,GAAGP,OAAO,CAAC,UAAD,CAAxB;;AACA,IAAMQ,YAAY,GAAGR,OAAO,CAAC,YAAD,CAA5B;AACA;AACA;AACA;;;AACA,IAAMS,cAAc,GAAG,EAAvB;AACA;AACA;AACA;AACA;AACA;AACA;;AACAZ,OAAO,CAACa,uCAAR,GAAkD,GAAlD;AACA;AACA;AACA;AACA;AACA;;AACA,IAAMC,uBAAuB,GAAG,GAAhC;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAMC,8BAA8B,GAAG,IAAI,EAAJ,GAAS,IAAhD;AACA;AACA;AACA;AACA;AACA;;IACMC,mB;AACF;AACJ;AACA;AACA;AACA;AACA;AACA;AACI,+BAAYC,GAAZ,EAAiBC,IAAjB,EAAuBC,MAAvB,EAA+BC,OAA/B,EAAwCC,SAAxC,EAAmD;AAAA;;AAC/C,SAAKJ,GAAL,GAAWA,GAAX;AACA,SAAKC,IAAL,GAAYA,IAAZ;AACA,SAAKC,MAAL,GAAcA,MAAd;AACA,SAAKC,OAAL,GAAeA,OAAf;AACA,SAAKC,SAAL,GAAiBA,SAAjB;AACA,SAAKC,QAAL,GAAgB,IAAIf,MAAM,CAACgB,QAAX,EAAhB;AACA,SAAKC,cAAL,GAAsB,CAAtB;AACH;;;;SACD,eAAc;AACV,aAAO,KAAKF,QAAL,CAAcG,OAArB;AACH;;;WACD,iBAAQC,KAAR,EAAe;AACX,QAAE,KAAKF,cAAP;;AACA,UAAI;AACA,YAAMG,eAAe,GAAG,IAAIC,eAAJ,CAAoBF,KAAK,CAACG,IAA1B,EAAgCH,KAAK,CAACI,OAAtC,EAA+C,KAAKb,GAApD,EAAyD,KAAKC,IAA9D,EAAoE,KAAKM,cAAzE,CAAxB;AACA,YAAMO,WAAW,GAAG,KAAKX,OAAL,CAAaO,eAAb,CAApB;AACAjB,QAAAA,QAAQ,CAACsB,MAAT,CAAgB,oBAAhB,EAAsC,IAAtC,EAA4C,mCAA5C,EAAiFN,KAAK,CAACG,IAAvF,EAA6F,gBAA7F,EAA+GE,WAA/G,EAA4H,gBAA5H,EAA8I,KAAKd,GAAL,CAASgB,IAAvJ;;AACA,YAAIF,WAAJ,EAAiB;AACb,eAAKZ,MAAL,CAAY,IAAZ;AACH,SAFD,MAGK;AACD,eAAKG,QAAL,CAAcY,MAAd,CAAqBP,eAArB;AACH;AACJ,OAVD,CAWA,OAAOQ,iBAAP,EAA0B;AACtB,aAAKb,QAAL,CAAcY,MAAd,CAAqBC,iBAArB;AACH;AACJ;;;WACD,mBAAUC,MAAV,EAAkB;AACd,UAAI;AACA,aAAKf,SAAL,CAAe,KAAKJ,GAApB,EAAyBmB,MAAzB;AACA,aAAKd,QAAL,CAAce,OAAd,CAAsBD,MAAtB;AACH,OAHD,CAIA,OAAOD,iBAAP,EAA0B;AACtB,aAAKb,QAAL,CAAcY,MAAd,CAAqBC,iBAArB;AACH;AACJ;;;;;AAEL;AACA;AACA;AACA;AACA;;;IACMG,e;;;;;AACF,6BAAc;AAAA;;AAAA;;AACV,+BAASC,SAAT,EADU,CAEV;;AACA,UAAKC,QAAL,GAAgB,IAAIC,GAAJ,EAAhB,CAHU,CAIV;AACA;;AACA,UAAKC,UAAL,GAAkB,EAAlB;AANU;AAOb;;;;WACD,aAAIC,WAAJ,EAAiB;AACb,aAAO,KAAKH,QAAL,CAAcI,GAAd,CAAkBD,WAAW,CAACV,IAA9B,CAAP;AACH;;;;iFACD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAiBY,gBAAAA,OAAjB,2DAA2B,EAA3B;AAEUC,gBAAAA,GAFV,GAEgB,CAACC,EAAE,GAAGF,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACG,UAAhE,MAAgF,IAAhF,IAAwFD,EAAE,KAAK,KAAK,CAApG,GAAwGA,EAAxG,GAA6GxC,MAAM,CAACyC,UAAP,EAF7H,EAGI;;AACMC,gBAAAA,KAJV,GAIkBC,KAAK,GAAGD,KAJ1B;AAAA;AAOQvC,gBAAAA,QAAQ,CAACsB,MAAT,CAAgB,4BAAhB,EAA8Cc,GAA9C,oCAA8E,KAAKK,QAAnF;AACMC,gBAAAA,UARd,GAQ2B7C,MAAM,CAAC8C,aAAP,CAAqB,YAArB,CAR3B;AAAA;AAAA,uBASyB,KAAKC,OAAL,CAAa;AAAEF,kBAAAA,UAAU,EAAVA,UAAF;AAAcG,kBAAAA,UAAU,EAAE,YAA1B;AAAwCP,kBAAAA,UAAU,EAAEF;AAApD,iBAAb,CATzB;;AAAA;AASQU,gBAAAA,QATR;AAAA;AAAA;;AAAA;AAAA;AAAA;AAYQ;AACMC,gBAAAA,GAbd,GAaoBC,KAAK,CAACC,IAAN,CAAW;AAAEC,kBAAAA,MAAM,EAAE,KAAKlB,UAAL,CAAgBkB;AAA1B,iBAAX,CAbpB;AAcQJ,gBAAAA,QAAQ,GAAG;AACPK,kBAAAA,YAAY,EAAEJ,GAAG,CAACK,GAAJ,CAAQ,YAAM;AACxB,2BAAO,EAAP;AACH,mBAFa,CADP;AAIPC,kBAAAA,MAAM,EAAEN,GAAG,CAACK,GAAJ,CAAQ;AAAA;AAAA,mBAAR;AAJD,iBAAX;;AAdR;AAqBI,qBAASE,CAAT,GAAa,CAAb,EAAgBA,CAAC,GAAG,CAACR,QAAQ,CAACK,YAAT,IAAyB,EAA1B,EAA8BD,MAAlD,EAA0D,EAAEI,CAA5D,EAA+D;AAC3D;AACA;AACA;AACMC,kBAAAA,yBAJqD,GAIzB3D,WAAW,CAAC4D,SAAZ,CAAsBC,UAAtB,CAAiC,CAAjC,CAJyB;AAKrDJ,kBAAAA,MALqD,GAK5C,CAACP,QAAQ,CAACO,MAAT,IAAmB,EAApB,EAAwBC,CAAxB,CAL4C;;AAM3D,sBAAID,MAAM,CAAClC,IAAP,KAAgBlB,YAAY,CAACyD,MAAb,CAAoBC,EAAxC,EAA4C;AAClCC,oBAAAA,UADkC,GACrBhE,WAAW,CAAC4D,SAAZ,CAAsBK,SAAtB,CAAgCf,QAAQ,CAACK,YAAT,CAAsBG,CAAtB,EAAyBM,UAAzB,IAAuCL,yBAAvE,CADqB;AAExC,yBAAKvB,UAAL,CAAgBsB,CAAhB,EAAmBQ,SAAnB,CAA6B,IAAIhE,aAAa,CAACiE,WAAlB,CAA8BH,UAA9B,CAA7B;AACH,mBAHD,MAIK;AACK5C,oBAAAA,KADL,GACa,IAAIf,YAAY,CAAC+D,WAAjB,CAA6BX,MAAM,CAACjC,OAAP,IAAkB6C,SAA/C,CADb;AAEDjD,oBAAAA,KAAK,CAACG,IAAN,GAAakC,MAAM,CAAClC,IAApB;AACA,yBAAKa,UAAL,CAAgBsB,CAAhB,EAAmBY,OAAnB,CAA2BrE,MAAM,CAACsE,SAAP,CAAiBnD,KAAjB,EAAwBuB,KAAxB,CAA3B;AACH;AACJ;;AApCL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAsCA;AACJ;AACA;AACA;;;;WACI,8BAAqB6B,EAArB,EAAyB;AACrB5E,MAAAA,MAAM,CAAC,CAAC,KAAKsC,QAAL,CAAcI,GAAd,CAAkBkC,EAAE,CAAC7D,GAAH,CAAOgB,IAAzB,CAAF,EAAkC,sDAAlC,CAAN;AACA,WAAKO,QAAL,CAAcuC,GAAd,CAAkBD,EAAE,CAAC7D,GAAH,CAAOgB,IAAzB;AACA,WAAKS,UAAL,CAAgBsC,IAAhB,CAAqBF,EAArB;AACH;;;;EA1DyBtE,aAAa,CAACyE,U;AA4D5C;AACA;AACA;AACA;AACA;;;IACMrD,e;;;;;AACF;AACA;AACA;AACAC,EAAAA,IAFA;AAGA;AACAC,EAAAA,OAJA;AAKA;AACAa,EAAAA,WANA;AAOA;AACAuC,EAAAA,aARA;AASA;AACA1D,EAAAA,cAVA,EAUgB;AAAA;;AAAA;;AACZ,gCAAMM,OAAN;AACA,WAAKD,IAAL,GAAYA,IAAZ;AACA,WAAKC,OAAL,GAAeA,OAAf;AACA,WAAKa,WAAL,GAAmBA,WAAnB;AACA,WAAKuC,aAAL,GAAqBA,aAArB;AACA,WAAK1D,cAAL,GAAsBA,cAAtB;AANY;AAOf;;;iCAnByB0B,K;;AAqB9BlD,OAAO,CAAC4B,eAAR,GAA0BA,eAA1B;AACA;AACA;AACA;AACA;AACA;AACA;;IACMuD,U;AACF;AACA,sBAAYC,SAAZ,EAAuBvC,OAAvB,EAAgC;AAAA;;AAC5B,QAAIE,EAAJ,EAAQsC,EAAR;;AACA,SAAKD,SAAL,GAAiBA,SAAjB;AACA;AACR;AACA;AACA;AACA;;AACQ,SAAKE,aAAL,GAAqB1E,cAArB;AACA;AACR;AACA;AACA;AACA;;AACQ,SAAK2E,gBAAL,GAAwB,IAAIjD,eAAJ,CAAoB,KAAK8C,SAAzB,CAAxB;AACA;AACR;AACA;AACA;AACA;;AACQ,SAAKI,OAAL,GAAeC,OAAO,CAACpD,OAAR,EAAf;AACA;AACR;AACA;AACA;AACA;AACA;;AACQ,SAAKqD,QAAL,GAAgB,KAAhB;AACA;AACR;AACA;AACA;AACA;;AACQ,SAAKC,UAAL,GAAkB,YAAM,CAAG,CAA3B;AACA;AACR;AACA;AACA;AACA;;;AACQ,SAAKC,QAAL,GAAgB,UAAAlE,KAAK,EAAI;AACrB,UAAM0B,UAAU,GAAG7C,MAAM,CAAC8C,aAAP,CAAqB,YAArB,CAAnB;AACA,aAAQ3B,KAAK,CAACG,IAAN,KAAe8C,SAAf,IACJvB,UAAU,CAACyC,QAAX,CAAoBnE,KAAK,CAACG,IAA1B,CADI,IAEJH,KAAK,CAACF,cAAN,GAAuBpB,SAAS,CAAC0F,kBAFrC;AAGH,KALD;;AAMA,SAAKV,SAAL,CAAeW,0BAAf;;AACAC,IAAAA,yBAAyB,CAACnD,OAAD,CAAzB;;AACA,QAAI,CAACA,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACoD,UAA3D,MAA2E,KAA/E,EAAsF;AAClF,WAAKC,YAAL,GAAoB,IAAI7F,cAAc,CAAC8F,WAAnB,CAA+BC,MAAM,CAACC,iBAAtC,EAAyDD,MAAM,CAACC,iBAAhE,EAAmFD,MAAM,CAACC,iBAA1F,EAA6GD,MAAM,CAACC,iBAApH,CAApB;AACH,KAFD,MAGK;AACD,UAAIC,YAAY,GAAGtG,OAAO,CAACa,uCAA3B;AACA,UAAI0F,OAAO,GAAGH,MAAM,CAACC,iBAArB;;AACA,UAAI,QAAQxD,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACoD,UAAlE,MAAkF,SAAtF,EAAiG;AAC7F,YAAI,CAAC,CAAClD,EAAE,GAAGF,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACoD,UAAhE,MAAgF,IAAhF,IAAwFlD,EAAE,KAAK,KAAK,CAApG,GAAwG,KAAK,CAA7G,GAAiHA,EAAE,CAACyD,eAArH,MAA0I7B,SAA9I,EAAyJ;AACrJ4B,UAAAA,OAAO,GAAG1D,OAAO,CAACoD,UAAR,CAAmBO,eAA7B;AACH;;AACD,YAAI,CAAC,CAACnB,EAAE,GAAGxC,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAK,KAAK,CAArC,GAAyC,KAAK,CAA9C,GAAkDA,OAAO,CAACoD,UAAhE,MAAgF,IAAhF,IAAwFZ,EAAE,KAAK,KAAK,CAApG,GAAwG,KAAK,CAA7G,GAAiHA,EAAE,CAACoB,mBAArH,MAA8I9B,SAAlJ,EAA6J;AACzJ2B,UAAAA,YAAY,GAAGzD,OAAO,CAACoD,UAAR,CAAmBQ,mBAAlC;AACH,SAN4F,CAO7F;AACA;AACA;AACA;;;AACA,YAAIF,OAAO,GAAGD,YAAd,EAA4B;AACxBA,UAAAA,YAAY,GAAGC,OAAf;AACH,SAb4F,CAc7F;AACA;;;AACA,YAAID,YAAY,GAAG,KAAKhB,aAAxB,EAAuC;AACnC,eAAKA,aAAL,GAAqBgB,YAArB;AACH;AACJ;;AACD,WAAKJ,YAAL,GAAoB,IAAI7F,cAAc,CAAC8F,WAAnB,CAA+BG,YAA/B,EAA6CxF,uBAA7C,EAAsEC,8BAAtE,EAAsGwF,OAAtG,CAApB;AACH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;WACI,gBAAO5D,WAAP,EAAoB+D,IAApB,EAA0B;AACtB,WAAKC,gBAAL;;AACA,UAAM7B,EAAE,GAAG,KAAK8B,QAAL,CAAcjE,WAAd,EAA2B,QAA3B,EAAqC,UAAAkE,eAAe;AAAA,eAAIA,eAAe,CAACC,MAAhB,CAAuBnE,WAAvB,EAAoC+D,IAApC,CAAJ;AAAA,OAApD,CAAX;;AACAnG,MAAAA,MAAM,CAACwG,cAAP,CAAsBjC,EAAtB;AACA,aAAOA,EAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,iBAAOnC,WAAP,EAAoBqE,YAApB,EAAkC;AAC9B,WAAKL,gBAAL;;AACA,UAAM7B,EAAE,GAAG,KAAK8B,QAAL,CAAcjE,WAAd,EAA2B,QAA3B,EAAqC,UAAAkE,eAAe;AAAA,eAAIA,eAAe,CAACI,MAAhB,CAAuBtE,WAAvB,EAAoCqE,YAApC,CAAJ;AAAA,OAApD,CAAX;;AACAzG,MAAAA,MAAM,CAACwG,cAAP,CAAsBjC,EAAtB;AACA,aAAOA,EAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,aAAInC,WAAJ,EAAiB+D,IAAjB,EAAuB7D,OAAvB,EAAgC;AAC5B,WAAK8D,gBAAL;;AACA,UAAM7B,EAAE,GAAG,KAAK8B,QAAL,CAAcjE,WAAd,EAA2B,KAA3B,EAAkC,UAAAkE,eAAe;AAAA,eAAIA,eAAe,CAACK,GAAhB,CAAoBvE,WAApB,EAAiC+D,IAAjC,EAAuC7D,OAAvC,CAAJ;AAAA,OAAjD,CAAX;;AACAtC,MAAAA,MAAM,CAACwG,cAAP,CAAsBjC,EAAtB;AACA,aAAOA,EAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,gBAAOnC,WAAP,EAAoBwE,WAApB,EAA0D;AAAA,wCAAtBC,oBAAsB;AAAtBA,QAAAA,oBAAsB;AAAA;;AACtD,WAAKT,gBAAL;;AACA,UAAM7B,EAAE,GAAG,KAAK8B,QAAL,CAAcjE,WAAd,EAA2B,QAA3B,EAAqC,UAAAkE,eAAe;AAAA,eAAIA,eAAe,CAACQ,MAAhB,OAAAR,eAAe,GAAQlE,WAAR,EAAqBwE,WAArB,SAAqCC,oBAArC,EAAnB;AAAA,OAApD,CAAX;;AACA7G,MAAAA,MAAM,CAACwG,cAAP,CAAsBjC,EAAtB;AACA,aAAOA,EAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,uBAAcwC,QAAd,EAAwB;AACpB,WAAK3B,UAAL,GAAkB2B,QAAlB;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,sBAAaC,mBAAb,EAAkC;AAC9B,WAAK3B,QAAL,GAAgB2B,mBAAhB;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,iBAAQ;AACJ,WAAKZ,gBAAL;;AACA,WAAKa,iBAAL;AAAuB;AAAa,UAApC;;AACA,aAAO,KAAKhC,OAAZ;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,iBAAQ;AACJ,WAAKmB,gBAAL;;AACA,WAAKvB,SAAL,CAAeqC,0BAAf;;AACA,UAAMC,YAAY,GAAG,KAAKC,KAAL,EAArB;AACA,WAAKjC,QAAL,GAAgB,IAAhB;AACA,aAAOgC,YAAP;AACH;AACD;AACJ;AACA;AACA;;;;WACI,4BAAmB;AACf,UAAI,KAAKhC,QAAT,EAAmB;AACf,cAAM,IAAIxC,KAAJ,CAAU,qCAAV,CAAN;AACH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,6BAAiC;AAAA;;AAAA,UAAfyE,KAAe,uEAAP,KAAO;AAC7B,UAAI,KAAKpC,gBAAL,CAAsBpC,QAAtB,KAAmC,CAAvC,EACI;AACJ,UAAML,GAAG,GAAGvC,MAAM,CAACyC,UAAP,EAAZ;AACA,UAAM4E,YAAY,GAAG,KAAKrC,gBAA1B;AACA,WAAKA,gBAAL,GAAwB,IAAIjD,eAAJ,CAAoB,KAAK8C,SAAzB,CAAxB,CAL6B,CAM7B;AACA;;AACA,UAAMyC,cAAc,GAAG,KAAK3B,YAAL,CAAkB4B,cAAlB,CAAiCF,YAAY,CAACzE,QAA9C,CAAvB;;AACA,UAAM4E,gBAAgB,GAAG,IAAIxH,MAAM,CAACgB,QAAX,EAAzB;;AACA,UAAIsG,cAAJ,EAAoB;AAChBE,QAAAA,gBAAgB,CAAC1F,OAAjB;AACH,OAFD,MAGK;AACD,YAAM2F,OAAO,GAAG,KAAK9B,YAAL,CAAkB+B,qBAAlB,CAAwCL,YAAY,CAACzE,QAArD,CAAhB;;AACAzC,QAAAA,QAAQ,CAACsB,MAAT,CAAgB,8BAAhB,EAAgDc,GAAhD,4BAAwEkF,OAAxE;AACA5H,QAAAA,SAAS,CAAC8H,cAAV,CAAyB;AAAA,iBAAMH,gBAAgB,CAAC1F,OAAjB,EAAN;AAAA,SAAzB,EAA2D2F,OAA3D;AACH;;AACDD,MAAAA,gBAAgB,CAACtG,OAAjB,CAAyB0G,IAAzB,wEAA8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBACpBP,YAAY,CAACQ,UAAb,CAAwB;AAAEpF,kBAAAA,UAAU,EAAEF;AAAd,iBAAxB,CADoB;;AAAA;AAE1B,oBAAI6E,KAAJ,EACI,MAAI,CAACH,iBAAL,CAAuBG,KAAvB;;AAHsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAA9B;AAKH;AACD;AACJ;AACA;AACA;;;;WACI,kBAAS1G,GAAT,EAAcC,IAAd,EAAoBmH,sBAApB,EAA4C;AACxC,UAAMC,YAAY,GAAG,IAAItH,mBAAJ,CAAwBC,GAAxB,EAA6BC,IAA7B,EAAmC,KAAKqH,OAAL,CAAaC,IAAb,CAAkB,IAAlB,EAAwBH,sBAAxB,CAAnC,EAAoF,KAAKzC,QAAL,CAAc4C,IAAd,CAAmB,IAAnB,CAApF,EAA8G,KAAK7C,UAAL,CAAgB6C,IAAhB,CAAqB,IAArB,CAA9G,CAArB;;AACA,WAAKD,OAAL,CAAaF,sBAAb,EAAqCC,YAArC;;AACA,aAAOA,YAAY,CAAC7G,OAApB;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;;WACI,iBAAQ4G,sBAAR,EAAgCvD,EAAhC,EAAoC;AAChC,UAAI,KAAKS,gBAAL,CAAsB3C,GAAtB,CAA0BkC,EAAE,CAAC7D,GAA7B,CAAJ,EAAuC;AACnC;AACA;AACA,aAAKuG,iBAAL;AACH,OAL+B,CAMhC;AACA;AACA;;;AACAa,MAAAA,sBAAsB,CAAC,KAAK9C,gBAAN,CAAtB;;AACA,WAAKA,gBAAL,CAAsBkD,oBAAtB,CAA2C3D,EAA3C;;AACA,WAAKU,OAAL,GAAe,KAAKA,OAAL,CAAa2C,IAAb,CAAkB;AAAA,eAAM5H,MAAM,CAACwG,cAAP,CAAsBjC,EAAE,CAACrD,OAAzB,CAAN;AAAA,OAAlB,CAAf;;AACA,UAAI,KAAK8D,gBAAL,CAAsBpC,QAAtB,KAAmC,KAAKmC,aAA5C,EAA2D;AACvD,aAAKkC,iBAAL;AACH;AACJ;;;;;;AAELxH,OAAO,CAACmF,UAAR,GAAqBA,UAArB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASa,yBAAT,CAAmC/F,KAAnC,EAA0C;AACtC,MAAIQ,UAAU,CAACiI,gBAAX,CAA4BzI,KAA5B,EAAmC;AAAE0I,IAAAA,QAAQ,EAAE;AAAZ,GAAnC,CAAJ,EAA4D;AACxD;AACH;;AACD,MAAMC,OAAO,GAAG,SAAhB;;AACA,MAAI,CAACrI,MAAM,CAACsI,QAAP,CAAgB5I,KAAhB,CAAL,EAA6B;AACzB,UAAM,IAAIiD,KAAJ,WAAazC,UAAU,CAACqI,sBAAX,CAAkCF,OAAlC,EAA2C,+BAA3C,CAAb,8BAAN;AACH;;AACD,MAAM/F,OAAO,GAAG5C,KAAhB;;AACA,MAAI4C,OAAO,CAACoD,UAAR,KAAuBtB,SAAvB,IACA,OAAO9B,OAAO,CAACoD,UAAf,KAA8B,SADlC,EAC6C;AACzC;AACH;;AACD,MAAIpD,OAAO,CAACoD,UAAR,CAAmBQ,mBAAnB,KAA2C9B,SAA/C,EAA0D;AACtDlE,IAAAA,UAAU,CAACsI,eAAX,CAA2B,qBAA3B,EAAkDlG,OAAO,CAACoD,UAAR,CAAmBQ,mBAArE,EAA0F;AACtFuC,MAAAA,QAAQ,EAAE;AAD4E,KAA1F;AAGH;;AACD,MAAInG,OAAO,CAACoD,UAAR,CAAmBO,eAAnB,KAAuC7B,SAA3C,EAAsD;AAClDlE,IAAAA,UAAU,CAACsI,eAAX,CAA2B,iBAA3B,EAA8ClG,OAAO,CAACoD,UAAR,CAAmBO,eAAjE,EAAkF;AAC9EwC,MAAAA,QAAQ,EAAE;AADoE,KAAlF;;AAGA,QAAInG,OAAO,CAACoD,UAAR,CAAmBQ,mBAAnB,KAA2C9B,SAA3C,IACA9B,OAAO,CAACoD,UAAR,CAAmBQ,mBAAnB,GACI5D,OAAO,CAACoD,UAAR,CAAmBO,eAF3B,EAE4C;AACxC,YAAM,IAAItD,KAAJ,WAAazC,UAAU,CAACqI,sBAAX,CAAkCF,OAAlC,EAA2C,+BAA3C,CAAb,uEAAN;AACH;AACJ;AACJ","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst assert = require(\"assert\");\nconst backoff_1 = require(\"./backoff\");\nconst rate_limiter_1 = require(\"./rate-limiter\");\nconst timestamp_1 = require(\"./timestamp\");\nconst util_1 = require(\"./util\");\nconst write_batch_1 = require(\"./write-batch\");\nconst validate_1 = require(\"./validate\");\nconst logger_1 = require(\"./logger\");\nconst google_gax_1 = require(\"google-gax\");\n/*!\n * The maximum number of writes that can be in a single batch.\n */\nconst MAX_BATCH_SIZE = 20;\n/*!\n * The starting maximum number of operations per second as allowed by the\n * 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\nexports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND = 500;\n/*!\n * The rate by which to increase the capacity as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\nconst RATE_LIMITER_MULTIPLIER = 1.5;\n/*!\n * How often the operations per second capacity should increase in milliseconds\n * as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\nconst RATE_LIMITER_MULTIPLIER_MILLIS = 5 * 60 * 1000;\n/**\n * Represents a single write for BulkWriter, encapsulating operation dispatch\n * and error handling.\n * @private\n */\nclass BulkWriterOperation {\n    /**\n     * @param ref The document reference being written to.\n     * @param type The type of operation that created this write.\n     * @param sendFn A callback to invoke when the operation should be sent.\n     * @param errorFn The user provided global error callback.\n     * @param successFn The user provided global success callback.\n     */\n    constructor(ref, type, sendFn, errorFn, successFn) {\n        this.ref = ref;\n        this.type = type;\n        this.sendFn = sendFn;\n        this.errorFn = errorFn;\n        this.successFn = successFn;\n        this.deferred = new util_1.Deferred();\n        this.failedAttempts = 0;\n    }\n    get promise() {\n        return this.deferred.promise;\n    }\n    onError(error) {\n        ++this.failedAttempts;\n        try {\n            const bulkWriterError = new BulkWriterError(error.code, error.message, this.ref, this.type, this.failedAttempts);\n            const shouldRetry = this.errorFn(bulkWriterError);\n            logger_1.logger('BulkWriter.errorFn', null, 'Ran error callback on error code:', error.code, ', shouldRetry:', shouldRetry, ' for document:', this.ref.path);\n            if (shouldRetry) {\n                this.sendFn(this);\n            }\n            else {\n                this.deferred.reject(bulkWriterError);\n            }\n        }\n        catch (userCallbackError) {\n            this.deferred.reject(userCallbackError);\n        }\n    }\n    onSuccess(result) {\n        try {\n            this.successFn(this.ref, result);\n            this.deferred.resolve(result);\n        }\n        catch (userCallbackError) {\n            this.deferred.reject(userCallbackError);\n        }\n    }\n}\n/**\n * Used to represent a batch on the BatchQueue.\n *\n * @private\n */\nclass BulkCommitBatch extends write_batch_1.WriteBatch {\n    constructor() {\n        super(...arguments);\n        // The set of document reference paths present in the WriteBatch.\n        this.docPaths = new Set();\n        // An array of pending write operations. Only contains writes that have not\n        // been resolved.\n        this.pendingOps = [];\n    }\n    has(documentRef) {\n        return this.docPaths.has(documentRef.path);\n    }\n    async bulkCommit(options = {}) {\n        var _a;\n        const tag = (_a = options === null || options === void 0 ? void 0 : options.requestTag) !== null && _a !== void 0 ? _a : util_1.requestTag();\n        // Capture the error stack to preserve stack tracing across async calls.\n        const stack = Error().stack;\n        let response;\n        try {\n            logger_1.logger('BulkCommitBatch.bulkCommit', tag, `Sending next batch with ${this._opCount} writes`);\n            const retryCodes = util_1.getRetryCodes('batchWrite');\n            response = await this._commit({ retryCodes, methodName: 'batchWrite', requestTag: tag });\n        }\n        catch (err) {\n            // Map the failure to each individual write's result.\n            const ops = Array.from({ length: this.pendingOps.length });\n            response = {\n                writeResults: ops.map(() => {\n                    return {};\n                }),\n                status: ops.map(() => err),\n            };\n        }\n        for (let i = 0; i < (response.writeResults || []).length; ++i) {\n            // Since delete operations currently do not have write times, use a\n            // sentinel Timestamp value.\n            // TODO(b/158502664): Use actual delete timestamp.\n            const DELETE_TIMESTAMP_SENTINEL = timestamp_1.Timestamp.fromMillis(0);\n            const status = (response.status || [])[i];\n            if (status.code === google_gax_1.Status.OK) {\n                const updateTime = timestamp_1.Timestamp.fromProto(response.writeResults[i].updateTime || DELETE_TIMESTAMP_SENTINEL);\n                this.pendingOps[i].onSuccess(new write_batch_1.WriteResult(updateTime));\n            }\n            else {\n                const error = new google_gax_1.GoogleError(status.message || undefined);\n                error.code = status.code;\n                this.pendingOps[i].onError(util_1.wrapError(error, stack));\n            }\n        }\n    }\n    /**\n     * Helper to update data structures associated with the operation and returns\n     * the result.\n     */\n    processLastOperation(op) {\n        assert(!this.docPaths.has(op.ref.path), 'Batch should not contain writes to the same document');\n        this.docPaths.add(op.ref.path);\n        this.pendingOps.push(op);\n    }\n}\n/**\n * The error thrown when a BulkWriter operation fails.\n *\n * @class BulkWriterError\n */\nclass BulkWriterError extends Error {\n    /** @hideconstructor */\n    constructor(\n    /** The status code of the error. */\n    code, \n    /** The error message of the error. */\n    message, \n    /** The document reference the operation was performed on. */\n    documentRef, \n    /** The type of operation performed. */\n    operationType, \n    /** How many times this operation has been attempted unsuccessfully. */\n    failedAttempts) {\n        super(message);\n        this.code = code;\n        this.message = message;\n        this.documentRef = documentRef;\n        this.operationType = operationType;\n        this.failedAttempts = failedAttempts;\n    }\n}\nexports.BulkWriterError = BulkWriterError;\n/**\n * A Firestore BulkWriter that can be used to perform a large number of writes\n * in parallel.\n *\n * @class BulkWriter\n */\nclass BulkWriter {\n    /** @hideconstructor */\n    constructor(firestore, options) {\n        var _a, _b;\n        this.firestore = firestore;\n        /**\n         * The maximum number of writes that can be in a single batch.\n         * Visible for testing.\n         * @private\n         */\n        this._maxBatchSize = MAX_BATCH_SIZE;\n        /**\n         * The batch that is currently used to schedule operations. Once this batch\n         * reaches maximum capacity, a new batch is created.\n         * @private\n         */\n        this._bulkCommitBatch = new BulkCommitBatch(this.firestore);\n        /**\n         * A pointer to the tail of all active BulkWriter applications. This pointer\n         * is advanced every time a new write is enqueued.\n         * @private\n         */\n        this._lastOp = Promise.resolve();\n        /**\n         * Whether this BulkWriter instance has started to close. Afterwards, no\n         * new operations can be enqueued, except for retry operations scheduled by\n         * the error handler.\n         * @private\n         */\n        this._closing = false;\n        /**\n         * The user-provided callback to be run every time a BulkWriter operation\n         * successfully completes.\n         * @private\n         */\n        this._successFn = () => { };\n        /**\n         * The user-provided callback to be run every time a BulkWriter operation\n         * fails.\n         * @private\n         */\n        this._errorFn = error => {\n            const retryCodes = util_1.getRetryCodes('batchWrite');\n            return (error.code !== undefined &&\n                retryCodes.includes(error.code) &&\n                error.failedAttempts < backoff_1.MAX_RETRY_ATTEMPTS);\n        };\n        this.firestore._incrementBulkWritersCount();\n        validateBulkWriterOptions(options);\n        if ((options === null || options === void 0 ? void 0 : options.throttling) === false) {\n            this._rateLimiter = new rate_limiter_1.RateLimiter(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);\n        }\n        else {\n            let startingRate = exports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND;\n            let maxRate = Number.POSITIVE_INFINITY;\n            if (typeof (options === null || options === void 0 ? void 0 : options.throttling) !== 'boolean') {\n                if (((_a = options === null || options === void 0 ? void 0 : options.throttling) === null || _a === void 0 ? void 0 : _a.maxOpsPerSecond) !== undefined) {\n                    maxRate = options.throttling.maxOpsPerSecond;\n                }\n                if (((_b = options === null || options === void 0 ? void 0 : options.throttling) === null || _b === void 0 ? void 0 : _b.initialOpsPerSecond) !== undefined) {\n                    startingRate = options.throttling.initialOpsPerSecond;\n                }\n                // The initial validation step ensures that the maxOpsPerSecond is\n                // greater than initialOpsPerSecond. If this inequality is true, that\n                // means initialOpsPerSecond was not set and maxOpsPerSecond is less\n                // than the default starting rate.\n                if (maxRate < startingRate) {\n                    startingRate = maxRate;\n                }\n                // Ensure that the batch size is not larger than the number of allowed\n                // operations per second.\n                if (startingRate < this._maxBatchSize) {\n                    this._maxBatchSize = startingRate;\n                }\n            }\n            this._rateLimiter = new rate_limiter_1.RateLimiter(startingRate, RATE_LIMITER_MULTIPLIER, RATE_LIMITER_MULTIPLIER_MILLIS, maxRate);\n        }\n    }\n    /**\n     * Create a document with the provided data. This single operation will fail\n     * if a document exists at its location.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * created.\n     * @param {T} data The object to serialize as the document.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .create(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n    create(documentRef, data) {\n        this._verifyNotClosed();\n        const op = this._enqueue(documentRef, 'create', bulkCommitBatch => bulkCommitBatch.create(documentRef, data));\n        util_1.silencePromise(op);\n        return op;\n    }\n    /**\n     * Delete a document from the database.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * deleted.\n     * @param {Precondition=} precondition A precondition to enforce for this\n     * delete.\n     * @param {Timestamp=} precondition.lastUpdateTime If set, enforces that the\n     * document was last updated at lastUpdateTime. Fails the batch if the\n     * document doesn't exist or was last updated at a different time.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the delete. If the delete fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .delete(documentRef)\n     *  .then(result => {\n     *    console.log('Successfully deleted document');\n     *  })\n     *  .catch(err => {\n     *    console.log('Delete failed with: ', err);\n     *  });\n     * });\n     */\n    delete(documentRef, precondition) {\n        this._verifyNotClosed();\n        const op = this._enqueue(documentRef, 'delete', bulkCommitBatch => bulkCommitBatch.delete(documentRef, precondition));\n        util_1.silencePromise(op);\n        return op;\n    }\n    /**\n     * Write to the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document does not\n     * exist yet, it will be created. If you pass [SetOptions]{@link SetOptions}.,\n     * the provided data can be merged into the existing document.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * set.\n     * @param {T} data The object to serialize as the document.\n     * @param {SetOptions=} options An object to configure the set behavior.\n     * @param {boolean=} options.merge - If true, set() merges the values\n     * specified in its data argument. Fields omitted from this set() call remain\n     * untouched.\n     * @param {Array.<string|FieldPath>=} options.mergeFields - If provided, set()\n     * only replaces the specified field paths. Any field path that is not\n     * specified is ignored and remains untouched.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .set(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n    set(documentRef, data, options) {\n        this._verifyNotClosed();\n        const op = this._enqueue(documentRef, 'set', bulkCommitBatch => bulkCommitBatch.set(documentRef, data, options));\n        util_1.silencePromise(op);\n        return op;\n    }\n    /**\n     * Update fields of the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document doesn't yet\n     * exist, the update fails and the entire batch will be rejected.\n     *\n     * The update() method accepts either an object with field paths encoded as\n     * keys and field values encoded as values, or a variable number of arguments\n     * that alternate between field paths and field values. Nested fields can be\n     * updated by providing dot-separated field path strings or by providing\n     * FieldPath objects.\n     *\n     *\n     * A Precondition restricting this update can be specified as the last\n     * argument.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * updated.\n     * @param {UpdateData|string|FieldPath} dataOrField An object containing the\n     * fields and values with which to update the document or the path of the\n     * first field to update.\n     * @param {...(Precondition|*|string|FieldPath)} preconditionOrValues - An\n     * alternating list of field paths and values to update or a Precondition to\n     * restrict this update\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .update(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n    update(documentRef, dataOrField, ...preconditionOrValues) {\n        this._verifyNotClosed();\n        const op = this._enqueue(documentRef, 'update', bulkCommitBatch => bulkCommitBatch.update(documentRef, dataOrField, ...preconditionOrValues));\n        util_1.silencePromise(op);\n        return op;\n    }\n    /**\n     * Attaches a listener that is run every time a BulkWriter operation\n     * successfully completes.\n     *\n     * @param callback A callback to be called every time a BulkWriter operation\n     * successfully completes.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteResult((documentRef, result) => {\n     *     console.log(\n     *       'Successfully executed write on document: ',\n     *       documentRef,\n     *       ' at: ',\n     *       result\n     *     );\n     *   });\n     */\n    onWriteResult(callback) {\n        this._successFn = callback;\n    }\n    /**\n     * Attaches an error handler listener that is run every time a BulkWriter\n     * operation fails.\n     *\n     * BulkWriter has a default error handler that retries UNAVAILABLE and\n     * ABORTED errors up to a maximum of 10 failed attempts. When an error\n     * handler is specified, the default error handler will be overwritten.\n     *\n     * @param shouldRetryCallback A callback to be called every time a BulkWriter\n     * operation fails. Returning `true` will retry the operation. Returning\n     * `false` will stop the retry loop.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteError((error) => {\n     *     if (\n     *       error.code === GrpcStatus.UNAVAILABLE &&\n     *       error.failedAttempts < MAX_RETRY_ATTEMPTS\n     *     ) {\n     *       return true;\n     *     } else {\n     *       console.log('Failed write at document: ', error.documentRef);\n     *       return false;\n     *     }\n     *   });\n     */\n    onWriteError(shouldRetryCallback) {\n        this._errorFn = shouldRetryCallback;\n    }\n    /**\n     * Commits all writes that have been enqueued up to this point in parallel.\n     *\n     * Returns a Promise that resolves when all currently queued operations have\n     * been committed. The Promise will never be rejected since the results for\n     * each individual operation are conveyed via their individual Promises.\n     *\n     * The Promise resolves immediately if there are no pending writes. Otherwise,\n     * the Promise waits for all previously issued writes, but it does not wait\n     * for writes that were added after the method is called. If you want to wait\n     * for additional writes, call `flush()` again.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await flush().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n    flush() {\n        this._verifyNotClosed();\n        this._sendCurrentBatch(/* flush= */ true);\n        return this._lastOp;\n    }\n    /**\n     * Commits all enqueued writes and marks the BulkWriter instance as closed.\n     *\n     * After calling `close()`, calling any method wil throw an error. Any\n     * retries scheduled as part of an `onWriteError()` handler will be run\n     * before the `close()` promise resolves.\n     *\n     * Returns a Promise that resolves when there are no more pending writes. The\n     * Promise will never be rejected. Calling this method will send all requests.\n     * The promise resolves immediately if there are no pending writes.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await close().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n    close() {\n        this._verifyNotClosed();\n        this.firestore._decrementBulkWritersCount();\n        const flushPromise = this.flush();\n        this._closing = true;\n        return flushPromise;\n    }\n    /**\n     * Throws an error if the BulkWriter instance has been closed.\n     * @private\n     */\n    _verifyNotClosed() {\n        if (this._closing) {\n            throw new Error('BulkWriter has already been closed.');\n        }\n    }\n    /**\n     * Sends the current batch and resets `this._bulkCommitBatch`.\n     *\n     * @param flush If provided, keeps re-sending operations until no more\n     * operations are enqueued. This allows retries to resolve as part of a\n     * `flush()` or `close()` call.\n     * @private\n     */\n    _sendCurrentBatch(flush = false) {\n        if (this._bulkCommitBatch._opCount === 0)\n            return;\n        const tag = util_1.requestTag();\n        const pendingBatch = this._bulkCommitBatch;\n        this._bulkCommitBatch = new BulkCommitBatch(this.firestore);\n        // Send the batch if it is under the rate limit, or schedule another\n        // attempt after the appropriate timeout.\n        const underRateLimit = this._rateLimiter.tryMakeRequest(pendingBatch._opCount);\n        const delayedExecution = new util_1.Deferred();\n        if (underRateLimit) {\n            delayedExecution.resolve();\n        }\n        else {\n            const delayMs = this._rateLimiter.getNextRequestDelayMs(pendingBatch._opCount);\n            logger_1.logger('BulkWriter._sendCurrentBatch', tag, `Backing off for ${delayMs} seconds`);\n            backoff_1.delayExecution(() => delayedExecution.resolve(), delayMs);\n        }\n        delayedExecution.promise.then(async () => {\n            await pendingBatch.bulkCommit({ requestTag: tag });\n            if (flush)\n                this._sendCurrentBatch(flush);\n        });\n    }\n    /**\n     * Schedules and runs the provided operation on the next available batch.\n     * @private\n     */\n    _enqueue(ref, type, enqueueOnBatchCallback) {\n        const bulkWriterOp = new BulkWriterOperation(ref, type, this._sendFn.bind(this, enqueueOnBatchCallback), this._errorFn.bind(this), this._successFn.bind(this));\n        this._sendFn(enqueueOnBatchCallback, bulkWriterOp);\n        return bulkWriterOp.promise;\n    }\n    /**\n     * Schedules the provided operations on current BulkCommitBatch.\n     * Sends the BulkCommitBatch if it reaches maximum capacity.\n     *\n     * @private\n     */\n    _sendFn(enqueueOnBatchCallback, op) {\n        if (this._bulkCommitBatch.has(op.ref)) {\n            // Create a new batch since the backend doesn't support batches with two\n            // writes to the same document.\n            this._sendCurrentBatch();\n        }\n        // Run the operation on the current batch and advance the `_lastOp` pointer.\n        // This ensures that `_lastOp` only resolves when both the previous and the\n        // current write resolves.\n        enqueueOnBatchCallback(this._bulkCommitBatch);\n        this._bulkCommitBatch.processLastOperation(op);\n        this._lastOp = this._lastOp.then(() => util_1.silencePromise(op.promise));\n        if (this._bulkCommitBatch._opCount === this._maxBatchSize) {\n            this._sendCurrentBatch();\n        }\n    }\n}\nexports.BulkWriter = BulkWriter;\n/**\n * Validates the use of 'value' as BulkWriterOptions.\n *\n * @private\n * @param value The BulkWriterOptions object to validate.\n * @throws if the input is not a valid BulkWriterOptions object.\n */\nfunction validateBulkWriterOptions(value) {\n    if (validate_1.validateOptional(value, { optional: true })) {\n        return;\n    }\n    const argName = 'options';\n    if (!util_1.isObject(value)) {\n        throw new Error(`${validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument')} Input is not an object.`);\n    }\n    const options = value;\n    if (options.throttling === undefined ||\n        typeof options.throttling === 'boolean') {\n        return;\n    }\n    if (options.throttling.initialOpsPerSecond !== undefined) {\n        validate_1.validateInteger('initialOpsPerSecond', options.throttling.initialOpsPerSecond, {\n            minValue: 1,\n        });\n    }\n    if (options.throttling.maxOpsPerSecond !== undefined) {\n        validate_1.validateInteger('maxOpsPerSecond', options.throttling.maxOpsPerSecond, {\n            minValue: 1,\n        });\n        if (options.throttling.initialOpsPerSecond !== undefined &&\n            options.throttling.initialOpsPerSecond >\n                options.throttling.maxOpsPerSecond) {\n            throw new Error(`${validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument')} \"maxOpsPerSecond\" cannot be less than \"initialOpsPerSecond\".`);\n        }\n    }\n}\n//# sourceMappingURL=bulk-writer.js.map"]},"metadata":{},"sourceType":"script"}